# Azure OpenAI Configuration
# Copy this file to .env.local and fill in your values

# Your Azure OpenAI API Key
# Get this from: Azure Portal > Your Resource > Keys and Endpoint
AZURE_OPENAI_API_KEY=your_api_key_here

# Your Azure OpenAI Endpoint
# Format: https://your-resource-name.openai.azure.com
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com

# Your Azure OpenAI Deployment Name
# This is the name you gave your model deployment in Azure
# Common values: gpt-4, gpt-35-turbo, gpt-4-turbo
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# (Optional) Override the API version if you are using Azure AI Foundry projects
# Leave unset to use the default `2024-08-01-preview`
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# (Optional) Provide a fully qualified chat completions URL if your Azure AI Foundry
# endpoint already includes the deployment path (for example when using project endpoints)
# AZURE_OPENAI_CHAT_COMPLETIONS_URL=https://your-endpoint.azure.com/openai/deployments/.../chat/completions

# --- Azure AI Foundry alternative variable names ---
# You can also use these instead of the AZURE_OPENAI_* names if that matches your setup.
# AZURE_AI_FOUNDRY_API_KEY=your_api_key_here
# AZURE_AI_FOUNDRY_ENDPOINT=https://your-project-endpoint.inference.azure.com
# AZURE_AI_FOUNDRY_DEPLOYMENT_NAME=gpt-4o-mini
# AZURE_AI_FOUNDRY_API_VERSION=2024-08-01-preview
